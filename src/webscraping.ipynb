{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Autoreload external files on execution\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Webscraping mit Pyhon: https://realpython.com/beautiful-soup-web-scraper-python/#scrape-the-fake-python-job-site\n",
    "\n",
    "python packages:\n",
    "\n",
    "```\n",
    "requests\n",
    "dataclasses\n",
    "beautifulsoup4\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "from databaseHelper import Person\n",
    "\n",
    "persons = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "UHH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uhh_url = \"https://www2.informatik.uni-hamburg.de/fiona/pers.php\"\n",
    "\n",
    "page = requests.get(uhh_url)\n",
    "soup = BeautifulSoup(page.content, \"html.parser\")\n",
    "\n",
    "result = []\n",
    "# get all rows of the person table (<tr>)\n",
    "for person in soup.find_all(name=\"tr\"):\n",
    "    # skip all rows without an id attribute\n",
    "    if not person.has_attr(\"id\"):\n",
    "        continue\n",
    "\n",
    "    # all table field values are insde <a> tags\n",
    "    fields = person.findAll(\"a\")\n",
    "\n",
    "    name = fields[1].text\n",
    "    department = fields[2].text\n",
    "\n",
    "    result.append(Person(\n",
    "        name=name,\n",
    "        university=\"Universität Hamburg\",\n",
    "        department=department\n",
    "    ))\n",
    "\n",
    "print(f\"done: scraped {len(result)} UHH staff\")\n",
    "persons.extend(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "HAW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "haw_url = \"https://www.haw-hamburg.de/hochschule/technik-und-informatik/departments/informatik/unser-department/beschaeftigte/\"\n",
    "\n",
    "page = requests.get(haw_url)\n",
    "soup = BeautifulSoup(page.content, \"html.parser\")\n",
    "\n",
    "result = []\n",
    "\n",
    "# loop over table rows\n",
    "for row in soup.findAll(\"div\", class_=\"row person-tile filter_tile border-top pt-4\"):\n",
    "    # find cell containing the name\n",
    "    person = row.find(\"div\", class_=\"col-12\")\n",
    "\n",
    "    name = \"\"\n",
    "    # extract title and name from html\n",
    "    for tag in person.findAll(\"a\", {\"title\" : \"Zur Profilseite\"}):\n",
    "        # title and name are in seperate <b> tags\n",
    "        for part in tag.findAll(\"b\"):\n",
    "            # remove whitespace\n",
    "            name += \" \" + re.sub(r\"\\s+\", \" \", part.text.strip())\n",
    "\n",
    "        result.append(Person(\n",
    "            name=name.strip(),\n",
    "            university=\"Hochschule für Angewandte Wissenschaften Hamburg\"\n",
    "        ))\n",
    "\n",
    "print(f\"done: scraped {len(result)} HAW staff\")\n",
    "persons.extend(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "split name into title and name\n",
    "\n",
    "for instance: \n",
    "`\"Prof. Dr. Klaus-Peter Kossakowski\"` becomes `\"Prof. Dr.\", \"Klaus-Peter Kossakowski\"`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for person in persons:\n",
    "    # chatGPT kann super so dumme regexe schreiben \n",
    "    pattern = r\"^(Prof\\. Dr\\.|Prof\\.|Dr\\.)(-Ing\\.| rer\\. nat\\.)?(?=.)(?:\\s|$)\"\n",
    "    \n",
    "    title = re.search(pattern, person.name)\n",
    "    \n",
    "    if not title: continue\n",
    "\n",
    "    person.title = title.group().strip()\n",
    "    person.name = re.sub(pattern, \"\", person.name).strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "insert persons into database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from databaseHelper import PersonDatabaseHelper\n",
    "\n",
    "dbHelper = PersonDatabaseHelper()\n",
    "\n",
    "dbHelper.deleteTable()\n",
    "dbHelper.createTable()\n",
    "\n",
    "dbHelper.insertPersons(persons)\n",
    "\n",
    "dbHelper.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for person in dbHelper.selectAll():\n",
    "    print(person)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
